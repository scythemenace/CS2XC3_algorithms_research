{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Science 2XC3 - Graded Lab II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this day and age, it is very easy to generate automated solutions to any problem, not necessarily becuase of AI, but because of vast online communities that exist to find solution to popular/common problems. Whether or not that solution is correct and applicable to our context,  can be assessed only if we understand the concepts and can critically evaluate them. The goal of this lab is to motivate you to not only produce the correct solution to problems, but also to reflect about why, how and when your solution will likely succeed/fail. \n",
    "\n",
    "In this lab you will design experiments with sorting and search algorithms. Please read all instructions carefully. Seek the help of TA's if you need clarifications on the task. Do not hard code any results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import timeit \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A1. Implement three classes with the following sorting algorithms:\n",
    "- Bubble Sort\n",
    "- Insertion Sort\n",
    "- Selection Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BubbleSort:\n",
    "    def __init__(self, items_to_sort):\n",
    "        self.items = items_to_sort\n",
    "        self.sorted_items=[]\n",
    "\n",
    "    ### your implementation for bubble sort goes here \n",
    "    def sort(self):\n",
    "        self.sorted_items = self.items.copy()\n",
    "        n = len(self.sorted_items)\n",
    "        for i in range(n):\n",
    "            swapped = False\n",
    "    \n",
    "            for j in range(0, n-i-1):\n",
    "                if self.sorted_items[j] > self.sorted_items[j+1]:\n",
    "                    self.sorted_items[j], self.sorted_items[j+1] = self.sorted_items[j+1], self.sorted_items[j]\n",
    "                    swapped = True\n",
    "            if (swapped == False):\n",
    "                break\n",
    "        \n",
    "    def get_sorted(self,):\n",
    "        return self.sorted_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsertionSort:\n",
    "    def __init__(self, items_to_sort):\n",
    "        self.items = items_to_sort\n",
    "        self.sorted_items=[]\n",
    "\n",
    "       ### your implementation for insertion sort goes here \n",
    "    def sort(self):\n",
    "        self.sorted_items = self.items.copy()\n",
    "        n = len(self.sorted_items)\n",
    "        for i in range(1, n):\n",
    "            key = self.sorted_items[i]\n",
    "            j = i-1\n",
    "            while j >= 0 and key < self.sorted_items[j] :\n",
    "                    self.sorted_items[j + 1] = self.sorted_items[j]\n",
    "                    j -= 1\n",
    "            self.sorted_items[j + 1] = key\n",
    "                \n",
    "    def get_sorted(self,):\n",
    "        return self.sorted_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectionSort:\n",
    "    def __init__(self, items_to_sort):\n",
    "        self.items = items_to_sort\n",
    "        self.sorted_items=[]\n",
    "\n",
    "       ### your implementation for selection sort goes here \n",
    "    def sort(self):\n",
    "        self.sorted_items = self.items.copy()\n",
    "        n = len(self.sorted_items)\n",
    "        for i in range(n):\n",
    "            min_index = i \n",
    "            for j in range(i+1, n): \n",
    "                if self.sorted_items[min_index] > self.sorted_items[j]: \n",
    "                    min_index = j \n",
    "                    \n",
    "            self.sorted_items[i], self.sorted_items[min_index] = self.sorted_items[min_index], self.sorted_items[i] \n",
    "            \n",
    "    def get_sorted(self,):\n",
    "        return self.sorted_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A2. Compute the performance of above 3 algorithms on a single list of real numbers.\n",
    "\n",
    "First generate a custom random list using function <code> create_custom_list()</code>. Execute each of the above algorithm for N trials ( select N >= 75) on the list and plot the timing of each execution on a bar chart. Also calculate the average execution time for the entire batch of N trials ( you can either display it on the chart or simply <code> print()</code> it). For larger values of N, consider breaking N trials into mini batches of n executions and plotting execution times for each mini batch. For instance, if you select N=1000, to plot execution timings for 1000 trials, you may break them into mini batch of n=10 trials and display average of each mini batch. This will reduce clutter in your bar charts while still enabling you to perform extensive testing with higher N.\n",
    "\n",
    "Execute each of the above algorithm on the same set of integers. The outcome of your code should be 3 charts for each algorithm run on your list N times. Few utility functions are given below. You do not have to necessarily use the <code> draw_plot()</code> function. You can plot your timings using an excel sheet and paste the image of your timings here. Refer to [Markdown Guide](https://www.markdownguide.org/basic-syntax/) on how to add images in the jupyter notebook or ask your TA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_list(length, max_value, item=None, item_index=None):\n",
    "    random_list = [random.randint(0,max_value) for i in range(length)]\n",
    "    if item!= None:\n",
    "        random_list.insert(item_index,item)\n",
    "    return random_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_plot(run_arr):\n",
    "    x = np.arange(0, len(run_arr),1)\n",
    "    fig=plt.figure(figsize=(20,8))\n",
    "    plt.bar(x,run_arr)\n",
    "    plt.axhline(np.mean(run_arr),color=\"red\",linestyle=\"--\",label=\"Avg\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Run time in ms order of 1e-6\")\n",
    "    plt.title(\"Run time for retrieval\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bubble sort experiment code goes here\n",
    "def bubble_sort_experiment():\n",
    "    bubble_sort_run_arr = []\n",
    "    for i in range(1000, 10001, 1000):\n",
    "        random_list = create_custom_list(i, 1000)\n",
    "        bubble_sort = BubbleSort(random_list)\n",
    "        start_time = timeit.default_timer()\n",
    "        bubble_sort.sort()\n",
    "        end_time = timeit.default_timer()\n",
    "        bubble_sort_run_arr.append((end_time - start_time)*1000000)\n",
    "    draw_plot(bubble_sort_run_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Insertion sort experiment code goes here\n",
    "def insertion_sort_experiment():\n",
    "    insertion_sort_run_arr = []\n",
    "    for i in range(1000, 10001, 1000):\n",
    "        random_list = create_custom_list(i, 1000)\n",
    "        insertion_sort = InsertionSort(random_list)\n",
    "        start_time = timeit.default_timer()\n",
    "        insertion_sort.sort()\n",
    "        end_time = timeit.default_timer()\n",
    "        insertion_sort_run_arr.append((end_time - start_time)*1000000)\n",
    "    draw_plot(insertion_sort_run_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Selection sort experiment code goes here\n",
    "def selection_sort_experiment():\n",
    "    selection_sort_run_arr = []\n",
    "    for i in range(1000, 10001, 1000):\n",
    "        random_list = create_custom_list(i, 1000)\n",
    "        selection_sort = SelectionSort(random_list)\n",
    "        start_time = timeit.default_timer()\n",
    "        selection_sort.sort()\n",
    "        end_time = timeit.default_timer()\n",
    "        selection_sort_run_arr.append((end_time - start_time)*1000000)\n",
    "    draw_plot(selection_sort_run_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You would notice that certain sorting algorithms have better time complexity (or performance) than others. Write below a reflection of your observations. Can you confidently compare the performance across the 3 algorithms? Why does certain algorithm perform better than the other? What are the various factors impacting the best performing and the worst performing algorithm. Write a few sentences answering each of the above questions. Also describe any other observation you found important.\n",
    "\n",
    "**Reflection**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A3. Compute the performance of above 3 algorithms on a different list sizes.\n",
    "\n",
    "The <code> create_custom_list()</code> helps you create lists of varying lengths and range of numbers. Plot a **line chart** that shows the performance of each algorithm on different list sizes ranging between 1 - 100,000 integers. If you think about this question, you are essentially plotting the time complexity on various list sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bubble sort experiment code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Insertion sort experiment code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Selection sort experiment code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe you results here. What did you observe when comparing the charts? Which algorithm was more performant and why?\n",
    "\n",
    "**Reflection** :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A4. Compute the performance of above 3 algorithms on a different list \"states\".\n",
    "\n",
    "Using the same above list generation function (or writing a function of your own), create two different lists states: \n",
    "\n",
    "- A state where the list is **near** sorted.\n",
    "- A state where the list is completely unsorted.\n",
    "\n",
    "HINTS: \n",
    "\n",
    "- You can implement a \"controlled\" Quicksort algorithm for such a function. While you can find many implementations of such a function online, significant number of those solutions originate from this psuedocode [Generating Sorted Lists of Random Numbers](https://dl.acm.org/doi/pdf/10.1145/355900.355907). \n",
    "\n",
    "- You can modify the list generation code given above to create the above list examples.\n",
    "\n",
    "Compare the performance of all 3 sorting algorithms on these two lists. Plot their performance on bar chart and display them here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bubble sort experiment code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Selection sort experiment code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Insertion sort experiment code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe you observations here. Which algorithm performs best / worst for sorted/near sorted lists and why? Does the performance vary significantly? Describe which runs times were higher and why do you think that is? You woul\n",
    "\n",
    "**Reflection** :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the class, we discussed three implementations of Binary Search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search_1(item_list, to_find):\n",
    "    lower=0\n",
    "    upper=len(item_list)-1\n",
    "    while lower < upper:\n",
    "        mid = (lower+upper)//2\n",
    "        if item_list[mid] == to_find:\n",
    "            return True\n",
    "        if item_list[mid] < to_find:\n",
    "            lower = mid+1\n",
    "        else:\n",
    "            upper=mid\n",
    "    return item_list[lower]==to_find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search_2(item_list, to_find):\n",
    "    lower=0\n",
    "    upper=len(item_list)-1\n",
    "    while lower <= upper:\n",
    "        mid = (lower+upper)//2\n",
    "        if item_list[mid] == to_find:\n",
    "            return True\n",
    "        if item_list[mid] < to_find:\n",
    "            lower = mid+1\n",
    "        else:\n",
    "            upper=mid-1\n",
    "    return item_list[lower]==to_find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search_3(item_list, to_find):\n",
    "    left=0\n",
    "    right=len(item_list)-1\n",
    "    while left != right:\n",
    "        mid = (left+right)//2\n",
    "        if item_list[mid] < to_find:\n",
    "            left = mid+1\n",
    "        elif item_list[mid] > to_find:\n",
    "            right = mid\n",
    "        else:\n",
    "            return True\n",
    "    return item_list[left]==to_find"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the performance of each implementation (or variation) with two lists:\n",
    "\n",
    "1. List is odd numbered (minimum 1000 integers)\n",
    "1. List is even numbered (minimum 1000 integers)\n",
    "\n",
    "Run the above experiments when the item to be found is:\n",
    "1. At the begining of the list.\n",
    "1. Towards the end of the list.\n",
    "1. Right at the middle of the list.\n",
    "\n",
    "The above three combinations would yield 3X2 experiments. Provide detailed outline of the experiments, plots, and a brief description of the observations in the reflections section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## you experiment code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reflection**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that I discussed in the class, the possibility of \"reducing the comparisons\" in Binary Search implementation. One solution came up is to remove the comparison with \"mid\". If you design an experiment to test this, you will soon realize that while this speeds up the execution time by reducing the number of comparisons needed, it fails when the element to be searched is right in the middle.  So are there any ways to improve the speed of Binary Search that is not dependent on data? The answer is recursion! In this section, implement a Binary Search recursively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search_4(item_list, to_find):\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run all the experiments in Part B comapring all 4 implementations under all 6 cases. Plot the timings, and describe the results in the below section. Write a short description of your observation; why is recursion better in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your implementation and experiments go here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Result Discussion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you are comfortable in designing experiments, in this section, use the implementations of **Heap**, **Merge**, and **Quick** sort discussed in class and run suitable experiments to compare the runtimes of these three algorithms. \n",
    "\n",
    "Hint: it should become clear where Quick sort gets its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your implementation and experiments go here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, provide a detailed outline of:\n",
    "- The experiments you ran, length values of the list you chose, number of runs, etc.\n",
    "- The plots showing the run times corresponding to each algorithm.\n",
    "- A brief discussion and conclusion regarding the results. A few sentences are fine here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E1. In previous experiments you also saw that not all algorithms are suitable for all scenarios. For instance, Merge Sort is better than Quick sort for certain situations. In this section, design a experiment to compare the scenarios where Merge Sort is better/worse than Quick Sort. You can use the traditional version of Merge Sort or use improved version ( maybe via recursion) to compare this performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your implementation and experiments go here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, provide a detailed outline of:\n",
    "- The experiments you ran, length values of the list you chose, number of runs, etc.\n",
    "- The plots showing the run times corresponding to each algorithm.\n",
    "- A brief discussion and conclusion regarding the results. A few sentences are fine here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E2. Recall that on the first day of class I asked which two algorithms have similar complexity - Merge Sort and Quick Sort under (O(nlogn)) are likely to perform similar under average cases. However, under worst case, the complexity of quick sort is much worse (O(n^2). Design an experiment to show this behavior. Plot this behavior on a bar/line chart. \n",
    "\n",
    "Next, count the number of \"swaps\" after which Quick sort starts behaving comparable to Merge sort. \n",
    "\n",
    "HINT: This will be a threshold at which the quick sort algorithm picks up again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your implementation and code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, provide a detailed outline of:\n",
    "- The experiments you ran and the rationale behind your worst case scenario.\n",
    "- The plots showing the run times.\n",
    "\n",
    "Further explain how you computed the swaps and verify that you calculation is correct, by applying it on a diifferent list under same experimental conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reflection**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditionally, Insertion Sort is worst than Heap Sort and Merge Sort. Now that you are a master at critical evaluation of sorting and searching algorithms, design an experiment to show that this may not be universally true. That is, there maybe scenarios where insertion sort is better than merge and heap sort.\n",
    "\n",
    "HINT: Think about the Best Case of insertion sort.\n",
    "\n",
    "Again, provide:\n",
    "- An explicit outline of the experiments you ran. That is, list length values, how many “runs”, etc.\n",
    "- A graph of list length vs time displaying the appropriate three curves showing. List lengths should be small here.\n",
    "- A brief discussion and conclusion regarding the results. A few sentences are fine here.\n",
    "- Reflect on why these are experiments are important. \n",
    "\n",
    "HINT: Can you create some sort of \"hybrid\" sort that would be better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your implementation and code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reflection**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Team Contributions**: In below section describe in detail how you distributed the workload and contributions of each member in the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
